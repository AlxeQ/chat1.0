import os
import tempfile
import pandas as pd
import streamlit as st
from docx import Document
import pdfplumber
import requests
import json
import time

# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œå¸ƒå±€
st.set_page_config(page_title="è®¿è°ˆæ™ºèƒ½æ•´ç†å™¨", layout="wide")

# æ ‡é¢˜å’Œä»‹ç»
st.title("ğŸ“ è®¿è°ˆæ™ºèƒ½æ•´ç†å™¨ (Smart Interview Sorter)")
st.markdown("""
    ä¸Šä¼ æ‚¨çš„è®¿è°ˆè®°å½•å’Œå¤§çº²ï¼Œå·¥å…·å°†è‡ªåŠ¨æ•´ç†å†…å®¹å¹¶è¯†åˆ«è¦†ç›–æƒ…å†µã€‚
    **ä½¿ç”¨DeepSeek APIè¿›è¡Œå†…å®¹åˆ†æ**
    """)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'processed' not in st.session_state:
    st.session_state.processed = False
if 'results' not in st.session_state:
    st.session_state.results = None
if 'interview_text' not in st.session_state:
    st.session_state.interview_text = ""
if 'outline_questions' not in st.session_state:
    st.session_state.outline_questions = []

# æ–‡ä»¶ä¸Šä¼ å’Œå¤„ç†å‡½æ•°
def extract_text_from_file(file):
    """æ ¹æ®æ–‡ä»¶ç±»å‹æå–æ–‡æœ¬"""
    text = ""
    
    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
    with tempfile.NamedTemporaryFile(delete=False) as tmp:
        tmp.write(file.getvalue())
        tmp_path = tmp.name
    
    try:
        if file.name.endswith('.pdf'):
            with pdfplumber.open(tmp_path) as pdf:
                text = "\n".join([page.extract_text() for page in pdf.pages if page.extract_text()])
        elif file.name.endswith('.docx'):
            doc = Document(tmp_path)
            text = "\n".join([para.text for para in doc.paragraphs if para.text])
        elif file.name.endswith('.txt'):
            with open(tmp_path, 'r', encoding='utf-8') as f:
                text = f.read()
    except Exception as e:
        st.error(f"æ–‡ä»¶å¤„ç†é”™è¯¯: {str(e)}")
    finally:
        os.unlink(tmp_path)
    
    return text

def extract_questions_from_outline(text):
    """ä»å¤§çº²æ–‡æœ¬ä¸­æå–é—®é¢˜"""
    # ç®€å•æŒ‰è¡Œåˆ†å‰²å¹¶è¿‡æ»¤ç©ºè¡Œ
    questions = [line.strip() for line in text.split('\n') if line.strip()]
    return questions

def analyze_with_deepseek(interview_text, questions):
    """ä½¿ç”¨DeepSeek APIåˆ†æè®¿è°ˆå†…å®¹"""
    # åœ¨ä¾§è¾¹æ è¾“å…¥çš„APIå¯†é’¥
    api_key = st.session_state.get('deepseek_api_key', '')
    
    if not api_key:
        st.error("è¯·å…ˆåœ¨ä¾§è¾¹æ è¾“å…¥DeepSeek APIå¯†é’¥")
        return None
    
    # æ„é€ æç¤ºè¯
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è®¿è°ˆå†…å®¹åˆ†æåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹è®¿è°ˆè®°å½•å†…å®¹ï¼Œå°†å›ç­”å¯¹åº”åˆ°ä»¥ä¸‹é—®é¢˜ä¸­ï¼Œå¹¶è¯„ä¼°è¦†ç›–æƒ…å†µ:

    === è®¿è°ˆè®°å½• ===
    {interview_text}

    === é—®é¢˜åˆ—è¡¨ ===
    {questions}

    è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¿”å›ç»“æœ:
    é—®é¢˜ | åŒ¹é…å†…å®¹æ‘˜è¦ | è¦†ç›–æƒ…å†µ(å……åˆ†/éƒ¨åˆ†/æœªè¦†ç›–) | å»ºè®®è¡¥é—®å†…å®¹

    è¦æ±‚:
    1. æ¯ä¸ªé—®é¢˜ä¸€è¡Œï¼Œå­—æ®µä¹‹é—´ç”¨ | åˆ†éš”
    2. åŒ¹é…å†…å®¹æ‘˜è¦è¦ç®€æ´ï¼Œä¸è¶…è¿‡50å­—
    3. è¦†ç›–æƒ…å†µè¯„ä¼°æ ‡å‡†:
       - å……åˆ†: æœ‰ç›´æ¥æ˜ç¡®çš„å›ç­”
       - éƒ¨åˆ†: æœ‰ç›¸å…³ä½†ä¸å®Œå…¨çš„å›ç­”
       - æœªè¦†ç›–: å®Œå…¨æ²¡æœ‰ç›¸å…³å†…å®¹
    4. å»ºè®®è¡¥é—®å†…å®¹è¦å…·ä½“å¯è¡Œ
    """
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": "deepseek-chat",
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è®¿è°ˆå†…å®¹åˆ†æåŠ©æ‰‹ã€‚"},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.3,
        "max_tokens": 2000
    }
    
    try:
        response = requests.post(
            "https://api.deepseek.com/v1/chat/completions",
            headers=headers,
            data=json.dumps(payload)
        )
        
        if response.status_code == 200:
            result = response.json()
            return result['choices'][0]['message']['content']
        else:
            st.error(f"DeepSeek APIé”™è¯¯: {response.status_code} - {response.text}")
            return None
    except Exception as e:
        st.error(f"APIè¯·æ±‚å¼‚å¸¸: {str(e)}")
        return None

def parse_response(response):
    """è§£æAPIè¿”å›çš„ç»“æœ"""
    lines = [line.strip() for line in response.split('\n') if line.strip() and '|' in line]
    data = []
    
    for line in lines:
        parts = [part.strip() for part in line.split('|')]
        if len(parts) >= 4:
            data.append({
                "å¤§çº²é—®é¢˜": parts[0],
                "åŒ¹é…å†…å®¹æ‘˜è¦": parts[1],
                "è¦†ç›–æƒ…å†µ": parts[2],
                "å»ºè®®è¡¥é—®": parts[3]
            })
        elif len(parts) == 3:
            data.append({
                "å¤§çº²é—®é¢˜": parts[0],
                "åŒ¹é…å†…å®¹æ‘˜è¦": parts[1],
                "è¦†ç›–æƒ…å†µ": parts[2],
                "å»ºè®®è¡¥é—®": "æ— "
            })
    
    return pd.DataFrame(data)

# ä¸»ç•Œé¢
if not st.session_state.processed:
    with st.form("upload_form"):
        st.subheader("1. ä¸Šä¼ æ–‡ä»¶")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ä¸Šä¼ è®¿è°ˆè®°å½•**")
            interview_file = st.file_uploader(
                "æ”¯æŒ .pdf æˆ– .docx æ ¼å¼",
                type=['pdf', 'docx'],
                key="interview_uploader",
                label_visibility="collapsed"
            )
        
        with col2:
            st.markdown("**ä¸Šä¼ è®¿è°ˆå¤§çº²**")
            outline_file = st.file_uploader(
                "æ”¯æŒ .docx æˆ– .txt æ ¼å¼",
                type=['docx', 'txt'],
                key="outline_uploader",
                label_visibility="collapsed"
            )
        
        submitted = st.form_submit_button("å¼€å§‹æ•´ç†")
        
        if submitted:
            if not interview_file or not outline_file:
                st.warning("è¯·ä¸Šä¼ è®¿è°ˆè®°å½•å’Œå¤§çº²æ–‡ä»¶")
            elif not st.session_state.get('deepseek_api_key'):
                st.warning("è¯·å…ˆåœ¨ä¾§è¾¹æ è¾“å…¥DeepSeek APIå¯†é’¥")
            else:
                with st.spinner("å¤„ç†æ–‡ä»¶ä¸­..."):
                    # æå–è®¿è°ˆæ–‡æœ¬
                    st.session_state.interview_text = extract_text_from_file(interview_file)
                    
                    # æå–å¤§çº²é—®é¢˜
                    outline_text = extract_text_from_file(outline_file)
                    st.session_state.outline_questions = extract_questions_from_outline(outline_text)
                    
                    # ä½¿ç”¨DeepSeekåˆ†æå†…å®¹
                    st.info("æ­£åœ¨ä½¿ç”¨DeepSeek APIåˆ†æè®¿è°ˆå†…å®¹ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...")
                    response = analyze_with_deepseek(
                        st.session_state.interview_text, 
                        st.session_state.outline_questions
                    )
                    
                    if response:
                        st.session_state.results = parse_response(response)
                        st.session_state.processed = True
                        st.rerun()

# ç»“æœæ˜¾ç¤ºé¡µé¢
if st.session_state.processed and st.session_state.results is not None:
    st.subheader("ğŸ“Š åˆ†æç»“æœ")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    coverage_counts = st.session_state.results['è¦†ç›–æƒ…å†µ'].value_counts()
    col1, col2, col3 = st.columns(3)
    col1.metric("æ€»é—®é¢˜æ•°", len(st.session_state.results))
    col2.metric("å……åˆ†è¦†ç›–", coverage_counts.get("å……åˆ†", 0))
    col3.metric("æœªè¦†ç›–", coverage_counts.get("æœªè¦†ç›–", 0))
    
    # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
    st.dataframe(
        st.session_state.results,
        use_container_width=True,
        hide_index=True,
        column_config={
            "å¤§çº²é—®é¢˜": "å¤§çº²é—®é¢˜",
            "åŒ¹é…å†…å®¹æ‘˜è¦": st.column_config.TextColumn(
                "åŒ¹é…å†…å®¹æ‘˜è¦",
                width="medium"
            ),
            "è¦†ç›–æƒ…å†µ": st.column_config.SelectboxColumn(
                "è¦†ç›–æƒ…å†µ",
                options=["å……åˆ†", "éƒ¨åˆ†", "æœªè¦†ç›–"],
                default="æœªè¦†ç›–"
            ),
            "å»ºè®®è¡¥é—®": st.column_config.TextColumn(
                "å»ºè®®è¡¥é—®",
                width="medium"
            )
        }
    )
    
    # æ·»åŠ ä¸‹è½½æŒ‰é’®
    excel_file = pd.ExcelWriter("interview_results.xlsx", engine='openpyxl')
    st.session_state.results.to_excel(excel_file, index=False)
    excel_file.close()
    
    with open("interview_results.xlsx", "rb") as file:
        st.download_button(
            label="ä¸‹è½½Excelæ–‡ä»¶",
            data=file,
            file_name="interview_results.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    
    # æ˜¾ç¤ºåŸå§‹å†…å®¹å’Œå¤§çº²é—®é¢˜
    with st.expander("æŸ¥çœ‹åŸå§‹è®¿è°ˆå†…å®¹"):
        st.text_area("è®¿è°ˆè®°å½•", st.session_state.interview_text, height=300)
    
    with st.expander("æŸ¥çœ‹å¤§çº²é—®é¢˜åˆ—è¡¨"):
        st.write(st.session_state.outline_questions)
    
    # é‡æ–°å¼€å§‹æŒ‰é’®
    if st.button("é‡æ–°å¼€å§‹"):
        st.session_state.processed = False
        st.session_state.results = None
        st.session_state.interview_text = ""
        st.session_state.outline_questions = []
        st.rerun()

# ä¾§è¾¹æ ä¿¡æ¯
with st.sidebar:
    st.markdown("## DeepSeek API è®¾ç½®")
    api_key = st.text_input(
        "DeepSeek APIå¯†é’¥",
        type="password",
        key="deepseek_api_key",
        help="è¯·ä»DeepSeekå¹³å°è·å–APIå¯†é’¥"
    )
    
    st.markdown("## ä½¿ç”¨è¯´æ˜")
    st.markdown("""
    1. è¾“å…¥DeepSeek APIå¯†é’¥
    2. ä¸Šä¼ è®¿è°ˆè®°å½•(PDF/DOCX)å’Œè®¿è°ˆå¤§çº²(DOCX/TXT)
    3. ç‚¹å‡»"å¼€å§‹æ•´ç†"æŒ‰é’®
    4. æŸ¥çœ‹åˆ†æç»“æœå¹¶ä¸‹è½½Excelæ–‡ä»¶
    """)
    
    st.markdown("## æ³¨æ„äº‹é¡¹")
    st.markdown("""
    - è®¿è°ˆè®°å½•åº”åŒ…å«å®Œæ•´çš„å¯¹è¯å†…å®¹
    - å¤§çº²æ–‡ä»¶åº”æ¯è¡Œä¸€ä¸ªä¸»è¦é—®é¢˜
    - åˆ†æç»“æœåŸºäºAIæ¨¡å‹ï¼Œå¯èƒ½éœ€è¦äººå·¥å¤æ ¸
    - è¯·å¦¥å–„ä¿ç®¡æ‚¨çš„APIå¯†é’¥
    """)
    
    st.markdown("---")
    st.markdown("**ç‰ˆæœ¬**: v1.1.0")
    st.markdown("**å¼€å‘è€…**: Your Name")

# éšè—Streamlité»˜è®¤æ ·å¼
hide_st_style = """
    <style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    </style>
"""
st.markdown(hide_st_style, unsafe_allow_html=True)